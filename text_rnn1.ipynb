{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-rnn1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJGSKdnfVx3nBDVw+z5QbJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giopnd/notebooks/blob/master/text_rnn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7UUn1bMUC1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "# check english lexicon\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import (\n",
        "    wordnet,\n",
        "    stopwords\n",
        ")\n",
        "\n",
        "# handle regular expressions\n",
        "import re\n",
        "\n",
        "# handle data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, Activation;\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#import libraries for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy30a5wpUt1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"georgiosgiotis\"\n",
        "os.environ['KAGGLE_KEY'] = \"78e14d9a6090bb989f7240761e76185b\"\n",
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle\n",
        "# Downlaod data\n",
        "!kaggle datasets download -d kazanova/sentiment140\n",
        "# unzip\n",
        "!unzip \"sentiment140.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRvGBUuPUpXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding='latin-1', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eUOuV4wVHmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data cleaning\n",
        "def preprocessing_text(df):\n",
        "  # lowercase\n",
        "  df = df.str.lower()\n",
        "  # remove retweets\n",
        "  df = df.str.replace('rt', '')\n",
        "  # remove mentions\n",
        "  df = df.replace(r'@\\w+', '', regex=True)\n",
        "  # remove links\n",
        "  df = df.replace(r'http\\S+', '', regex=True)\n",
        "  df = df.replace(r'www.[^ ]+', '', regex=True)\n",
        "  # remove numbers\n",
        "  df = df.replace(r'[0-9]+', '', regex=True)\n",
        "  # remove special characters and puntuation marks\n",
        "  df = df.replace(r'[!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]', '', regex=True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSp7CyhYU-dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data0 = data[0].apply(lambda x: int(x)/4)\n",
        "data5 = data[5]\n",
        "\n",
        "data5 = preprocessing_text(data5)\n",
        "\n",
        "# split data into training and test dataset\n",
        "def split(dfd, dfl):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(dfd, dfl, test_size=0.2, shuffle=True)\n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "x_train, x_test, y_train, y_test = split(data5[::64], data0[::64])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ19EEH1gvhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "for sent_str in data5:\n",
        "  tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
        "  sentences.append(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzuPwz6yU5Ap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb53716c-bfe0-4d75-ed0b-20586403610b"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model_ted = Word2Vec(sentences=sentences, size=100, window=5, min_count=5, workers=8, sg=0)\n",
        "\n",
        "#model_ted.wv.most_similar('house')\n",
        "\n",
        "print(len(model_ted.wv.vocab))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56071\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}